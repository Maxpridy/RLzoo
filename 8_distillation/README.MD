# 8. distillation

이걸 뭐라고 불러야할지 잘 모르겠다. teacher student? 내가 이미지쪽 경량화에 약해서 그쪽에선 이런 이름으로 불릴텐데 그것과 약간 유사할지도 모르겠다. 일단 distillation이란 단어가 많이 사용되는걸로 알고있기 때문에 통칭해서 부르겠다.

이름이야 어찌되었든 여기서 살펴보려고 하는 주요 개념을 짚어보면
- 작은 모델에서 큰 모델로
- 복잡한 리워드에서 간단한(궁극적인) 리워드로
- teacher모델을 student모델로

첫번째줄의 중요성은 학습 속도이다. 이게 우습게 볼 주제가 아니라는것은 강화학습 학습시켜본 사람들은 누구나 알것이다. 내가 알고싶은건 이 가속의 속도가 궁금한것이다. 이 부분에 대한 실험을 직접 진행할 예정이다.

두번째줄은 어찌보면 알파고 같은 굉장히 간단한 reward 시스템으로 학습시켰던 논문들에 적용할 수 있는 방법이면서 만약 게임이 좀 더 복잡했다면(바둑이 단순한 게임인건 사실이기 때문에) 행동을 유도할 수 있는 좋은 방법이다. exploration으로 찾기 힘든 행동들을 강제로 학습시킬 수 있다는 점에서 이것또한 학습 속도 개선에 큰 영향을 미칠 수 있다.

세번째는 근본적인 이 모델의 방법론으로, 뭐 별거 없다. 모델끼리 KL divergence로 학습시키는것이다.

직접 실험을 진행해볼 예정인데 사실 env를 어떤걸 선택할지. 직접 만든다면 어떤 env를 만들어야 실험이 잘될지 등이 되게 고민이 많이된다. 하지만 굉장히 중요한 부분이기 때문에 env를 만드는 과정에 대한 고민도 담을 예정이다.