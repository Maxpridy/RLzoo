# multi processing

여기에선 RL에서 멀티프로세싱을 구현한 구현체들에 대해서 알아보자

주된 이야기거리는 "어떤 구현이 좋을까?" 이다. 사실 구현들을 보면 비슷한데 약간씩은 차이점이 있다. 어디서는 이 부분을 직접 구현하고 어디서는 저 부분을 torch를 가져다쓰고... 어디서는 cc를 구현해서 import하여 사용한다. 뭐가 좋고 뭐가 나쁜지 파악하며 병렬 학습에 대한 감을 잡는것이 가장 큰 목적이다.

multi processing을 이용하는 알고리즘들은 기본적으로 일반화 성능 등에서 뛰어날 수 밖에 없지만 나같은 컴퓨팅 자원도 부족하고 그만큼 무거운 환경을 돌릴수도 없는 사람은 지금까지 알아보기도 좀 어려웠다. 마치 GPT-3를 학습시키거나 하는 이야기에 가깝다고 느껴진다. 하지만 여러 구현체가 나오면서 간접적으로 어떻게 구현하는것이 좋아보인다~ 정도는 알 수 있게 되었다고 생각되어서 단락을 작성하게 되었다. 특히 이번 축구 대회에서 임팔라를 사용한 팀이 꽤나 많았기 때문에 실전적인 필요성을 많이 느끼게 되었다. 

1, 2번에선 임팔라, vtrace에 대한 이야기
3, 4번에선 PPO, APPO에 대한 이야기를 할것이다.
5번은 그냥 넣어봤다. 많은 구현이 있는곳이라 참고할만하기 때문에...

1. torchbeast(IMPALA)
2. HandyRL(IMPALA)
3. paris팀(Synchronous-PPO)
4. obs-tower2(Synchronous-PPO)
5. RLlib(IMPALA/APPO/PPO)