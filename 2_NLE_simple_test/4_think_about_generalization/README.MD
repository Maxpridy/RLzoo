# 4. 일반화에 대해 생각해보기

(이번엔 실험이 아니라 그냥 생각해본다. 실험을 해보고 싶지만 이건 좀 품이 많이들 것 같고 논문에도 어느정도 잘 나와있다.)

최신 강화학습 알고리즘들을 보면 atari에서 사람들도 잘 못하거나 특수한 sequence를 가지고 있는 게임들도 이제는 잘 한다는것을 볼 수 있다. 그런것들을 보면서 내가 생각했던건 '정말 이 게임 하는법을 알아냈는가'이다. 어찌보면 아타리는 사람이 하는것과 별 차이가 없는것 같기도 하다. 문제는 조금씩 더 복잡해지는 게임에서의 해결 능력을 근본적으로 배울 수 있는지의 여부이다. 

논문 3-1과 Figure3에 일반화에 대한 설명이 나와있는데, 이부분이 내가 이 환경을 고른 또하나의 이유기도 하다. 환경이 충분히 복잡하기 때문에 일반화에 대한 논의를 할만하다고 생각된다. 그림3에서 보여주듯이 train은 여러 시드일 때 return이 내려가는걸 볼 수 있다. 그리고 특이하게도 staircase에 대해 출력노드의 히든노드 숫자가 적당해야 제일 좋은 성능이 나왔다고 한다. 사실 좀 미심쩍지만 뭐 어느정도 일반화가 되긴 된다는것을 보여주는듯하다. 

내가 느끼는 문제는 여기서부터인데 이 상황에서 어떤 task를 이해했다 라는 수준에 다다르는것이 굉장히 까다롭다. 어떤 특정한 지식(이 환경에 있는 돈, 음식, 내려가기, 특정한 목표 등등)을 이루기 위해선 정말 막대한 학습이 필요하다. 계속 변하는 시드에서 어떤 작업을 수행한다는건 정말 그 작업 자체를 이해했다 라고 할만큼 학습을 많이 시켜야 하는듯하다.

이 부분은 정말 진정한 인공지능이 무엇인가에 대한 생각과도 좀 이어지는것 같다. '단순히 데이터를 많이 보고 학습했으니까, 그걸 잘 판단하도록 weights들이 구성되어 있으니까 지능이다.' 라기엔 아직은 너무 부족한면이 많지 않나싶다. 우리가 AI나 인공지능이란 말을 볼때면 약간 머쓱해하면서도 거부감을 느끼는 이유는 그런면이 있는것같다.

사실 기준이 너무 높은것도 있다. 인간은 사실 소수 말고는 게임을 그렇게 잘하지 않는다. 그러니까 논문에서 나오는 인간 평균성능이 그정도로 나오는것이다.