# further imitation

캐글 축구 대회에서 무얼 배울 수 있었느냐... 순수한 강화학습은 엄청난 연산이 든다는 것이다. 뭐 자세한건 다른 repo에 있는 캐글 참가에 대한걸 읽어보면 알수있겠지만 7등은 2등에 대한 순수한 imitation이다. 그 imitation을 여러가지 각도에서 이기려는 시도를 해보는것이 의미가 있지 않을까 싶어서 시도해보기로 했다.

## 목적 : 2021.01.12

다시 말하자면 목적은 7등을 이겨보는것이다. 왜 이런 목적을 정했냐면... 1등 2등은 이기기 힘들고(상대할 수 있는 모델도 없고) 3등은 모범적으로 imitation -> RL을 했지만 정확한 학습코드를 공개하진 않았고 4등은 모르겠고 5등은 강화학습, 6등도 강화학습이다. 그 이후 7등이 imitation learning인데, 1등과 2등의 데이터를 통해 7등을 이길 수 있다면 imitation에 대한 공부가 되지 않을까? 하는 생각이 들어서, 그리고 나아가서 3등까지도 이길 수 있다면 많은 공부가 될거라는 생각이 들었다.

## 기존 모델들 테스트 : 2021.01.13

일단 3등(WeKick)과 7등(s_toppo)를 붙여보면 리더보드 상에서는 3등이 일반적으로 이긴다. 7등은 사실 공개된 버전은 1400점 정도라고 했으니 12위권이라고 봐야하고 3등은 아마도 설명을 보면 최종 제출본이라고 생각된다. 근데 막상 성능을 보면... 흠 잘 모르겠다.

7등(12위권) 코드에 다른 데이터를 넣어서 테스트를 해보았다. 

데이터셋을 조금 분류해보면  
1. 위에서 말한 80게임쯤 되는 1위를 기록한 제출물의 경기 기록
2. WeKick의 293게임. 내가 만듦. 바로위에서 말한 학습시도해본 데이터셋
3. WeKick의 300게임. 다른사람이 만든거
4. SaltyFish의 375게임. 7위가 학습한 데이터셋

가장 먼저 시도해볼만한것은 이 데이터셋들에 대해서 7위의 코드로 학습해보았다. 그리고 존재하는 모델들과 100게임씩 붙여보았다. 쉽게 우열을 가릴 수 없어서 안그래도 환경이 느린데 100게임이나 치뤄야한다니 느리다 느려..

- 3위WK vs 3위SF  
19 : 65, draw : 16  
33 : 47, draw : 20  
왜인지는 몰라도 3위 RawBeast는 SF쪽 모델이 훨씬 강하다.

- 3위SF vs 7위의 마이너버전(4번 데이터셋)  
15 : 65, draw : 20  
38 : 42, draw : 20  
26 : 47, draw : 27  
58 : 28, draw : 14(prob sample, 나머진 max)  
? 왜 7위가 이기는거지...? 리더보드에서 3위의 기록을 보면 7위 만난건 다이겼는데 정말 3위는 최종제출물이 아닌거같기도 하다.

- 3위SF vs 7위 마이너버전(1번 데이터셋)  
87 : 3, draw : 10  
데이터셋이 부족한 탓인지 좀 부족한 모습을 보임

- 3위SF vs 7위 마이너버전(2번 데이터셋)  
44 : 39, draw : 17  
역시 SF가 강하다. 

- 3위SF vs 7위 마이너버전(3번 데이터셋)  
37 : 45, draw : 18  
WK를 imitation한것이 생각보다 잘한다.

- 7위 마이너버전(4번 데이터셋) vs 7위 마이너버전(3번 데이터셋)  
59 : 23, draw : 18  
확실하게 SF를 배운것이 더 강하다는걸 보여준다.

- 7위 마이너버전(4번 데이터셋) vs 메모리패턴 v47  
94 : 1, draw : 5(max)  
82 : 7, draw : 11(prob sample)  
압도적인 승리

전반적으로 WK을 imitation한 모델은 강한 성능을 내지 못한다. 3등도 7등도 SF를 imitation한 모델이 더 강하다. 이유가 뭘까?

첫번째로 생각해 볼 수 있는 부분은 WeKick은 초기 버전에서 SaltyFish보다 약했다. WeKick 팀은 마지막에 제출하던 버전들이 매우 강하다.  
두번째로는 WeKick은 여러가지 전략에 대한 에이전트를 시도해봤던것 같다. 정확히는 모르겠지만 solution을 읽어보면 별 이상한 전략(공가지고 가만히있기, 키퍼에게 패스한 뒤 롱패스)들을 다 학습해서 적용한걸 볼 수 있다. 그렇기 때문에 일관된 전략이 아닐 가능성이 높을지 모른다. 일관되지 않은 전략들이 모이면 아무래도 학습하기가 더 어려울것이다.


## 컴퓨팅 자원에 대해 또... : 2021.01.13

캐글 노트북은 일반적인 컴퓨터들과 어느정도 비슷한 성능이고 내가 가지고있는건 일반적인 성능의 컴퓨터다. 그래서 캐글 노트북을 쓰는게 지금 상황에서 제일 낫다. 일단 데이터를 옮기는 작업 자체가 굉장히 간단하다는점이 가장 장점이다. 단점이라면 만족스럽다고 하긴 애매한 성능과 커널 시간이 짧아서 자꾸 끊기는것이 매우 신경쓰인다는점이다. 

결국 내 상황에서는 캐글 노트북이 최선이라는것이 좀 슬프지만 일단 해보는것에 의의를 두고싶다. 혹은 방향이 정해진다면 하나의 방향으로 로컬에서 테스트를 해볼 수도 있겠다.


## 첫번째 테스트. catboost모델을 JS를 통해 학습하기 : 2021.01.16

첫번째 테스트는 catboost모델(7위, 4번 데이터셋)을 JS divergence를 통해 학습시키는 것이다. 상대는 메모리 패턴 v47로 일단 정하고 학습했다.

기본적으로 catboost모델은 v47을 압도하므로 JS 통해 단순히 학습하는걸로 얼마의 성능이 나오는지를 테스트하는것이 목적이다.

- 2021.01.21  
SPS가 역시 정말 낮다... 겨우 몇백 episode 확인하는게 전부인데 학습이 되는둥 마는둥 해서 꽤 힘들다. 하루에 대충 250 에피소드정도 진행이 되는데 너무느려서 커널 시간관리도 어렵고 축축 쳐진다. 위에서 테스트해보았지만 stochastic한 policy라 해도 v47은 압도하는 모습을 보이는데 학습을 좀 거쳐도 압도하지는 못하고 그냥저냥 이기거니 지거니 비슷한 수준을 보이고 있다. 학습이 아주 잘되는건 아니라고 확인된다. 다른걸 하면서 같이 천천히 여러가지 시도를 해보아야겠다.

- 2021.01.28  
와.. 다른거 좀 하면서 계속 imitation을 시도했는데 쉽지가 않다. 강력한 성능을 내진 못해도 어느정돈 따라할줄 알았는데 v47을 이기거니 지거니 하는정도로밖에 성능을 내지 못한다. 일단 지금까지 학습한 모델을 불러와서 catboost를 기반으로 강화학습 하는걸로 넘어가보자.


## 두번째 테스트. 위 모델을 불러와서 JS+강화학습 : 2021.01.28

방법은 여러 모델의 방법을 조금씩 가져왔다. 피쳐는 7위, 리워드모델은 6위, 이런식으로 짬뽕해서 좋아보이는걸 섞었다.

당연히 드라마틱한 성능개선은 없다. 샘플링이 받쳐주지 못하는데 될리가 없다. 

- 2021.02.07  
이제 1000 에피소드쯤 진행되었다. 세션 신경쓰기가 어렵다보니까 저장 못하고 놓치는것도 있고 세션때마다 실행 속도가 약간씩 달라서 에피소드 수를 정해놓고 commit하기도 애매한것같고... 